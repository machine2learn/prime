{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "field_id = \"f.eid\"\n",
    "map_ukbb_freindly_name = {\n",
    "    20023: \"snap_game_true_pos_rt_avrg\",\n",
    "    401: \"snap_game_index_card_a\",\n",
    "    402: \"snap_game_index_card_b\",\n",
    "    403: \"snap_game_number_button_presses\",\n",
    "    404: \"snap_game_ms_first_press\",\n",
    "    399: \"pairs_matching_incorrect_in_round\",\n",
    "    400: \"pairs_matching_completion_time_round\",\n",
    "    20132: \"online_pairs_matching_incorrect_in_round\",\n",
    "    # 20133: \"online_pairs_matching_completion_time_round\",\n",
    "    20134: \"date_online_pairs_comletion\",\n",
    "    4282: \"num_memory_max_digits_remembered_correctly\",\n",
    "    4285: \"num_memory_completion_time\",\n",
    "    53: \"date_visit\",\n",
    "    21022: \"age_visit\",\n",
    "    6138: \"qualifications\",\n",
    "    \n",
    "}\n",
    "'''1\tCollege or University degree\n",
    "2\tA levels/AS levels or equivalent\n",
    "3\tO levels/GCSEs or equivalent\n",
    "4\tCSEs or equivalent\n",
    "5\tNVQ or HND or HNC or equivalent\n",
    "6\tOther professional qualifications eg: nursing, teaching\n",
    "-7\tNone of the above\n",
    "-3\tPrefer not to answer '''\n",
    "\n",
    "# version https://academic.oup.com/ije/article/49/1/246/5470096\n",
    "'''(College or University degree, vocational qualifications (other professional qualifications/NVQ or HND or HNC), \n",
    "optional national exams at ages 17 to 18 years (A levels/AS levels), \n",
    "national exams at age 16 years (O levels/GCSEs/CSEs), none of the above, unknown (prefer not to answer))'''\n",
    "education_level_map = {\n",
    "    1 : 3,\n",
    "    2: 2,\n",
    "    3: 1,\n",
    "    4: 1,\n",
    "    5: 3,\n",
    "    6: 3\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Dietary article\n",
    "Participants who completed the repeat assessment centre visit or at least one 24-h dietary assessment were more likely to have a university degree or vocational qualification and slightly less likely to smoke, compared with the full cohort.\n",
    "\n",
    "'''\n",
    "\n",
    "n_samples = None# limit #samples for debug\n",
    "data_filename = \"/projects/prime/ukbb/23_01_2024_selected.tab\"\n",
    "output_dir = \"/projects/prime/ukbb/preprocessed_data_2024/\"\n",
    "out_file = output_dir + \"cognitive_2024_maart.csv\"\n",
    "\n",
    "withdrawn_participants_file = '/projects/prime/ukbb/withdraw6244_207_20231205.txt'\n",
    "# data_filename = '~/PRIME/python_raw_cognitive_tmp_distorted.csv'\n",
    "withdrawn = pd.read_csv(withdrawn_participants_file, header=None)\n",
    "withdrawn_col = list(withdrawn.iloc[:, 0])\n",
    "\n",
    "### find out the list of all columns\n",
    "data_columns = pd.read_table(data_filename, nrows=1, sep='\\t').columns\n",
    "\n",
    "# make a list of columns needed\n",
    "needed_fields = [\"f.eid\"]\n",
    "for ukbb_field in map_ukbb_freindly_name:\n",
    "    print(ukbb_field)\n",
    "    current_list = [col for col in data_columns if col.startswith(\"f.\" +str(ukbb_field))]\n",
    "    needed_fields = needed_fields + current_list\n",
    "    print(current_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start reading the table .... \")\n",
    "\n",
    "df = pd.read_table(data_filename, sep='\\t', usecols=needed_fields, dtype=str, nrows=n_samples)\n",
    "\n",
    "print(\"finished reading the table .... \")\n",
    "print(\"# participants before checking entrance age\")\n",
    "print(len(df))\n",
    "df = df[~df[\"f.21022.0.0\"].isnull()]\n",
    "print(\"# participants after checking entrance age but yet with withdrawn \")\n",
    "print(len(df))\n",
    "\n",
    "df = df[~df[field_id].isin(withdrawn_col)]\n",
    "\n",
    "print(\"# participants without withdrawn \")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_fields = {}\n",
    "for i in range(4): # over instances (visits)\n",
    "    for ukbb_field, friendly_name in map_ukbb_freindly_name.items():\n",
    "        \n",
    "        if i>0 and friendly_name.startswith(\"age_visit\"):\n",
    "            continue\n",
    "        \n",
    "        if i>0 and friendly_name.startswith(\"online\"):\n",
    "            continue\n",
    "        \n",
    "        if friendly_name.startswith(\"qualifications\"):\n",
    "            for j in range(6): # multiple answers were possible\n",
    "                source=f\"f.{str(ukbb_field)}.{i}.{j}\"\n",
    "                df[source] = df[source].astype(float)\n",
    "                target=f\"{friendly_name}.{i}.{j}\"\n",
    "                map_fields[source] =target \n",
    "            continue\n",
    "        \n",
    "        if friendly_name.startswith(\"pairs_matching\"):\n",
    "            for j in [1,2,3]: # three rounds, but we will consider the sume of errors of 1 and 2, and just the first round as alternative\n",
    "                source=f\"f.{str(ukbb_field)}.{i}.{j}\"\n",
    "                df[source] = df[source].astype(float)\n",
    "                target = f\"{friendly_name}_{j}.{i}\" \n",
    "                map_fields[source] =target \n",
    "            continue\n",
    "        \n",
    "        if friendly_name.startswith(\"online_pairs_matching\"):\n",
    "            for j in [0,1,2]: # three rounds, but we will consider the sume of errors of 1 and 2, and just the first round as alternative\n",
    "                source=f\"f.{str(ukbb_field)}.{i}.{j}\"\n",
    "                df[source] = df[source].astype(float)\n",
    "                target = f\"{friendly_name}_{j+1}.{i}\" \n",
    "                map_fields[source] =target \n",
    "            continue\n",
    "        \n",
    "        source = f\"f.{str(ukbb_field)}.{i}.0\"\n",
    "        if not friendly_name.startswith(\"date_visit\") and not friendly_name.startswith(\"date_online_pairs_comletion\"):\n",
    "            df[source] = df[source].astype(float)\n",
    "        target = f\"{friendly_name}.{i}\" \n",
    "        map_fields[source] = target\n",
    "       \n",
    "        \n",
    "print(map_fields)\n",
    "df.rename(columns=map_fields, inplace=True)\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df[\"age_visit.0\"].ge(48)]\n",
    "for i in range(4):\n",
    "    for j in range(1,4):\n",
    "        df.loc[df[f\"pairs_matching_completion_time_round_{j}.{i}\"].le(0), f\"pairs_matching_incorrect_in_round_{j}.{i}\"] = np.NaN\n",
    "\n",
    "'''\n",
    "for j in range(1,4):\n",
    "        df.loc[df[f\"online_pairs_matching_completion_time_round_{j}.{i}\"].le(0), f\"online_pairs_matching_incorrect_in_round_{j}.{i}\"] = np.NaN\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pairs matching sum incorrect for two rounds\n",
    "assignment = {}\n",
    "    \n",
    "for i in range(4):\n",
    "    assignment[f\"pairs_matching_sum_incorrect.{i}\"] = df[f\"pairs_matching_incorrect_in_round_1.{i}\"] + df[f\"pairs_matching_incorrect_in_round_2.{i}\"]\n",
    "    \n",
    "df = df.assign(**assignment)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make education levels\n",
    "assignment = {}\n",
    "for i in range(4):\n",
    "    # initialise education level\n",
    "    target_fld_name = f\"education_level.{i}\"\n",
    "    src_fld_name = f\"qualifications.{i}.0\"\n",
    "    assignment[target_fld_name] = df[src_fld_name].map(education_level_map)\n",
    "    df = df.assign(**assignment) \n",
    "    for j in range(1,6):\n",
    "        src_fld_name = f\"qualifications.{i}.{j}\"\n",
    "        df.loc[~df[target_fld_name].isnull() & ~df[src_fld_name].map(education_level_map).isnull(), target_fld_name] = np.maximum(df[target_fld_name], df[src_fld_name].map(education_level_map))\n",
    "        df.loc[df[target_fld_name].isnull(), target_fld_name] = df[src_fld_name].map(education_level_map) \n",
    "                                                                                                                                \n",
    "        \n",
    "        \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment = {}\n",
    "assignment[\"time_difference.0.1\"] = (pd.to_datetime(df[\"date_visit.1\"]) - pd.to_datetime(df[\"date_visit.0\"])).dt.total_seconds() / (24 * 3600)\n",
    "assignment[\"time_difference.0.2\"] = (pd.to_datetime(df[\"date_visit.2\"]) - pd.to_datetime(df[\"date_visit.0\"])).dt.total_seconds() / (24 * 3600)\n",
    "assignment[\"time_difference.0.3\"] = (pd.to_datetime(df[\"date_visit.3\"]) - pd.to_datetime(df[\"date_visit.0\"])).dt.total_seconds() / (24 * 3600)\n",
    "df = df.assign(**assignment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"num_memory_max_digits_remembered_correctly.0\"].lt(0), \"num_memory_max_digits_remembered_correctly.0\"] = np.NaN\n",
    "df.loc[df[\"num_memory_max_digits_remembered_correctly.2\"].lt(0), \"num_memory_max_digits_remembered_correctly.2\"] = np.NaN\n",
    "df.loc[df[\"num_memory_max_digits_remembered_correctly.3\"].lt(0), \"num_memory_max_digits_remembered_correctly.3\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assignment = {}\n",
    "for i in range(1,4):\n",
    "    # per round\n",
    "    for j in range(1,4):\n",
    "        assignment[f\"pairs_matching_change_round_{j}.0.{i}\"] = df[f\"pairs_matching_incorrect_in_round_{j}.{i}\"] - df[f\"pairs_matching_incorrect_in_round_{j}.0\"]\n",
    "        assignment[f\"pairs_matching_change_rate_round_{j}.0.{i}\"] = (assignment[f\"pairs_matching_change_round_{j}.0.{i}\"] * 365.25) / df[f\"time_difference.0.{i}\"] \n",
    "\n",
    "    # for the sum incorrect\n",
    "    assignment[f\"pairs_matching_sum_incorrect_change.0.{i}\"] = df[f\"pairs_matching_sum_incorrect.{i}\"] - df[\"pairs_matching_sum_incorrect.0\"]     \n",
    "    assignment[f\"pairs_matching_sum_incorrect_change_rate.0.{i}\"] = (assignment[f\"pairs_matching_sum_incorrect_change.0.{i}\"]  * 365.25) / df[f\"time_difference.0.{i}\"] \n",
    "    \n",
    "    # snap game\n",
    "    assignment[f\"snap_game_true_pos_rt_avrg_change.0.{i}\"] = df[f\"snap_game_true_pos_rt_avrg.{i}\"] - df[\"snap_game_true_pos_rt_avrg.0\"]     \n",
    "    assignment[f\"snap_game_true_pos_rt_avrg_change_rate.0.{i}\"] = (assignment[f\"snap_game_true_pos_rt_avrg_change.0.{i}\"]  * 365.25) / df[f\"time_difference.0.{i}\"] \n",
    "    \n",
    "    # numeric memory\n",
    "    assignment[f\"numeric_memory_change.0.{i}\"] = df[f\"num_memory_max_digits_remembered_correctly.{i}\"] - df[\"num_memory_max_digits_remembered_correctly.0\"]\n",
    "    assignment[f\"numeric_memory_change_rate.0.{i}\"] = (assignment[f\"numeric_memory_change.0.{i}\"]  * 365.25) / df[f\"time_difference.0.{i}\"] \n",
    "    \n",
    "df = df.assign(**assignment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assignment = {}\n",
    "for i in range(1,4):\n",
    "    # per round\n",
    "    for j in range(1,4):\n",
    "        assignment[f\"pairs_matching_change_round_{j}.0.{i}\"] = df[f\"pairs_matching_incorrect_in_round_{j}.{i}\"] - df[f\"pairs_matching_incorrect_in_round_{j}.0\"]\n",
    "        assignment[f\"pairs_matching_change_rate_round_{j}.0.{i}\"] = (assignment[f\"pairs_matching_change_round_{j}.0.{i}\"] * 365.25) / df[f\"time_difference.0.{i}\"] \n",
    "\n",
    "    # for the sum incorrect\n",
    "    assignment[f\"pairs_matching_sum_incorrect_change.0.{i}\"] = df[f\"pairs_matching_sum_incorrect.{i}\"] - df[\"pairs_matching_sum_incorrect.0\"]     \n",
    "    assignment[f\"pairs_matching_sum_incorrect_change_rate.0.{i}\"] = (assignment[f\"pairs_matching_sum_incorrect_change.0.{i}\"]  * 365.25) / df[f\"time_difference.0.{i}\"] \n",
    "    \n",
    "    # snap game\n",
    "    assignment[f\"snap_game_true_pos_rt_avrg_change.0.{i}\"] = df[f\"snap_game_true_pos_rt_avrg.{i}\"] - df[\"snap_game_true_pos_rt_avrg.0\"]     \n",
    "    assignment[f\"snap_game_true_pos_rt_avrg_change_rate.0.{i}\"] = (assignment[f\"snap_game_true_pos_rt_avrg_change.0.{i}\"]  * 365.25) / df[f\"time_difference.0.{i}\"] \n",
    "    \n",
    "    # numeric memory\n",
    "    assignment[f\"numeric_memory_change.0.{i}\"] = df[f\"num_memory_max_digits_remembered_correctly.{i}\"] - df[\"num_memory_max_digits_remembered_correctly.0\"]\n",
    "    assignment[f\"numeric_memory_change_rate.0.{i}\"] = (assignment[f\"numeric_memory_change.0.{i}\"]  * 365.25) / df[f\"time_difference.0.{i}\"] \n",
    "    \n",
    "df = df.assign(**assignment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"pairs_matching_sum_incorrect_change.0.2\"])\n",
    "print(df[\"numeric_memory_change.0.2\"])\n",
    "print(df[\"snap_game_true_pos_rt_avrg_change.0.2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# online: we need for learning effect for the second visit\n",
    "assignment = {\"learning_effect_prior.2\": np.NaN, \"online_before.2\": None}\n",
    "\n",
    "df = df.assign(**assignment)\n",
    "df.loc[df[f\"pairs_matching_incorrect_in_round_1.2\"].notnull(), \"learning_effect_prior.2\"] = 0\n",
    "df[\"online_before.2\"] = (pd.to_datetime(df[\"date_visit.2\"]) - pd.to_datetime(df[\"date_online_pairs_comletion.0\"])).dt.total_seconds().ge(0)\n",
    "print(df[\"online_before.2\"])\n",
    "for j in range(1,4):\n",
    "    df.loc[df[f\"pairs_matching_incorrect_in_round_{j}.1\"].notnull(), \"learning_effect_prior.2\"] = df[\"learning_effect_prior.2\"] + 1\n",
    "    df.loc[df[\"online_before.2\"] & df[f\"online_pairs_matching_incorrect_in_round_{j}.0\"].notnull(), \"learning_effect_prior.2\"] = df[\"learning_effect_prior.2\"] + 1\n",
    "\n",
    "print(df[\"learning_effect_prior.2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(out_file, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_checkup_nm = df[~df[\"num_memory_max_digits_remembered_correctly.0\"].isnull() &\n",
    "                    ~df[\"num_memory_max_digits_remembered_correctly.2\"].isnull()]\n",
    "df_checkup_nm_sg = df_checkup_nm[~df_checkup_nm[\"snap_game_true_pos_rt_avrg.0\"].isnull() &\n",
    "                                    ~df_checkup_nm[\"snap_game_true_pos_rt_avrg.2\"].isnull()]\n",
    "df_checkup_nm_sg_edu =df_checkup_nm_sg[~df_checkup_nm_sg[\"education_level.0\"].isnull()]\n",
    "print(f\"participants with nm and sg both visits with edu defined: {len(df_checkup_nm_sg_edu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all three cognitive tests\n",
    "df_checkup_nm_sg_pm_1_edu = df_checkup_nm_sg_edu[~df_checkup_nm_sg_edu[\"pairs_matching_incorrect_in_round_1.0\"].isnull() &\n",
    "                                    ~df_checkup_nm_sg_edu[\"pairs_matching_incorrect_in_round_1.2\"].isnull()]\n",
    "print(f\"participants with nm, pm_1,  and sg three visits with edu defined: {len(df_checkup_nm_sg_pm_1_edu)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkup_nm_sg_pm_edu = df_checkup_nm_sg_edu[~df_checkup_nm_sg_edu[\"pairs_matching_sum_incorrect.0\"].isnull() &\n",
    "                                    ~df_checkup_nm_sg_edu[\"pairs_matching_sum_incorrect.2\"].isnull()]\n",
    "print(f\"participants with nm, pm,  and sg both visits with edu defined: {len(df_checkup_nm_sg_pm_edu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkup_pm_1 = df[~df[\"pairs_matching_incorrect_in_round_1.0\"].isnull() &\n",
    "                    ~df[\"pairs_matching_incorrect_in_round_1.2\"].isnull()]\n",
    "df_checkup_pm_1_sg = df_checkup_pm_1[~df_checkup_pm_1[\"snap_game_true_pos_rt_avrg.0\"].isnull() &\n",
    "                                    ~df_checkup_pm_1[\"snap_game_true_pos_rt_avrg.2\"].isnull()]\n",
    "\n",
    "df_checkup_pm_1_sg_edu =df_checkup_pm_1_sg[~df_checkup_pm_1_sg[\"education_level.0\"].isnull()]\n",
    "print(f\"participants with pm_1 and sg both visits with edu defined: {len(df_checkup_pm_1_sg_edu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit 0 and 1\n",
    "df_01_checkup_pm_1 = df[~df[\"pairs_matching_incorrect_in_round_1.0\"].isnull() &\n",
    "                    ~df[\"pairs_matching_incorrect_in_round_1.1\"].isnull()]\n",
    "df_01_checkup_pm_1_sg = df_01_checkup_pm_1[~df_01_checkup_pm_1[\"snap_game_true_pos_rt_avrg.0\"].isnull() &\n",
    "                                    ~df_01_checkup_pm_1[\"snap_game_true_pos_rt_avrg.1\"].isnull()]\n",
    "\n",
    "df_01_checkup_pm_1_sg_edu =df_01_checkup_pm_1_sg[~df_01_checkup_pm_1_sg[\"education_level.0\"].isnull()]\n",
    "print(f\"participants with pm_1 and sg both visits 0 and 1 with edu defined: {len(df_01_checkup_pm_1_sg_edu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkup_pm = df[~df[\"pairs_matching_sum_incorrect.0\"].isnull() &\n",
    "                    ~df[\"pairs_matching_sum_incorrect.2\"].isnull()]\n",
    "df_checkup_pm_sg = df_checkup_pm[~df_checkup_pm[\"snap_game_true_pos_rt_avrg.0\"].isnull() &\n",
    "                                    ~df_checkup_pm[\"snap_game_true_pos_rt_avrg.2\"].isnull()]\n",
    "df_checkup_pm_sg_edu =df_checkup_pm_sg[~df_checkup_pm_sg[\"education_level.0\"].isnull()]\n",
    "print(f\"participants with pm and sg both visits with edu defined: {len(df_checkup_pm_sg_edu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_checkup_pm = df[~df[\"pairs_matching_sum_incorrect.0\"].isnull() &\n",
    "                    ~df[\"pairs_matching_sum_incorrect.1\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_checkup_pm_sg = df_01_checkup_pm[~df_01_checkup_pm[\"snap_game_true_pos_rt_avrg.0\"].isnull() &\n",
    "                                    ~df_01_checkup_pm[\"snap_game_true_pos_rt_avrg.1\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_checkup_pm_sg_edu =df_01_checkup_pm_sg[~df_01_checkup_pm_sg[\"education_level.0\"].isnull()]\n",
    "\n",
    "print(f\"participants with pm and sg both visits 0 and 1 with edu defined: {len(df_checkup_pm_sg_edu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkup_nm_sg_pm_1_edu[\"time_difference.0.2\"].plot(kind='hist', title='Density time_difference.0.2 for all nm, pm_1, sg, with edu.0 defined')\n",
    "plt.show()\n",
    "\n",
    "df_checkup_nm_sg_pm_edu[\"time_difference.0.2\"].plot(kind='hist', title='Density time_difference.0.2 for all nm, pm, sg with edu.0 defined')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_checkup_nm_sg_edu[\"time_difference.0.2\"].plot(kind='hist', title='Density time_difference.0.2 for all nm, sg with edu.0 defined')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkup_pm_1_sg_edu[\"time_difference.0.2\"].plot(kind='hist', title='Density time_difference.0.2 for all pm_1, sg, edu defined')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkup_pm_sg_edu[\"time_difference.0.2\"].plot(kind='hist', title='Density time_difference.0.2 for all pm, sg, edu defined ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_checkup_pm_1_sg_edu[\"time_difference.0.1\"].plot(kind='hist', title='Density time_difference.0.1 for all pm_1, sg, edu defined ')\n",
    "plt.show()\n",
    "df_01_checkup_pm_sg_edu[\"time_difference.0.1\"].plot(kind='hist', title='Density time_difference.0.1 for all pm, sg, edu defined ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_trends(dataset, predictor, colname_, step, name_data_set, cat = False):\n",
    "    min_predictor = np.min(dataset[predictor])\n",
    "    max_predictor = np.max(dataset[predictor])\n",
    "    if cat:\n",
    "        lower_bound = min_predictor\n",
    "        upper_bound = max_predictor + 1\n",
    "    else:\n",
    "        lower_bound = min_predictor + step\n",
    "        upper_bound = max_predictor \n",
    "    row_list_median = []\n",
    "    row_list_mean = []\n",
    "    val = lower_bound\n",
    "    while val < upper_bound:\n",
    "        df_current = pd.DataFrame()\n",
    "        if cat:\n",
    "          df_current = dataset[dataset[predictor].eq(val)] \n",
    "        else:\n",
    "            df_current = dataset[dataset[predictor].ge(val-step) &\n",
    "                                                    dataset[predictor].le(val+step)]\n",
    "           \n",
    "        if len(df_current) == 0:\n",
    "            val = val + step \n",
    "            continue\n",
    "        row_list_median.append([val, np.median(df_current[colname_])])\n",
    "        row_list_mean.append([val, np.mean(df_current[colname_])])\n",
    "        val = val + step \n",
    "\n",
    "    matrix_median = np.array(row_list_median)\n",
    "    matrix_mean = np.array(row_list_mean)\n",
    "    print(\"******\")\n",
    "    print(\"Here is the report on \")\n",
    "    print(name_data_set)\n",
    "    \n",
    "    if cat:\n",
    "        \n",
    "        plt.scatter(matrix_median[:,0], matrix_median[:,1], label = \"median\")\n",
    "        plt.scatter(matrix_mean[:,0], matrix_mean[:,1], label = \"mean\")\n",
    "    else:\n",
    "        plt.plot(matrix_median[:,0], matrix_median[:,1], label = \"median\")\n",
    "        plt.plot(matrix_mean[:,0], matrix_mean[:,1], label = \"mean\")\n",
    "    plt.xlabel(predictor)\n",
    "    plt.ylabel(colname_)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(f\"sample size {len(dataset)}\")\n",
    "    std_dev = np.std(dataset[colname_])\n",
    "    variance = np.var(dataset[colname_])\n",
    "    data_range = np.ptp(dataset[colname_])  # Peak to peak (max-min)\n",
    "    iqr = np.subtract(*np.percentile(dataset[colname_], [75, 25]))  # 75th percentile - 25th percentile\n",
    "    # cv = std_dev / np.mean(dataset[colname_])\n",
    "    print(f\"Standard Deviation: {std_dev}\")\n",
    "    print(f\"Variance: {variance}\")\n",
    "    print(f\"Range: {data_range}\")\n",
    "    print(f\"IQR: {iqr}\")\n",
    "    # print(f\"Coefficient of Variation: {cv}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all thre cognitive tests, pm round 1\n",
    "print('****')\n",
    "print(\"Change all thre cognitive tests, pm round 1\")\n",
    "\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"age_visit.0\", \"numeric_memory_change.0.2\", 1, \"nm_sg_pm_1_edu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"age_visit.0\", \"numeric_memory_change_rate.0.2\", 1, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"time_difference.0.2\", \"numeric_memory_change.0.2\", 30, \"nm_sg_pm_1_edu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"time_difference.0.2\", \"numeric_memory_change_rate.0.2\", 30, \"nm_sg_pm_1_edu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_trends(df_checkup_nm_sg_pm_1_edu, \"time_difference.0.2\", \"test\", 30, \"nm_sg_pm_1_edu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"education_level.0\", \"numeric_memory_change.0.2\", 1, \"nm_sg_pm_1_edu\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"age_visit.0\", \"snap_game_true_pos_rt_avrg_change.0.2\", 1, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"time_difference.0.2\", \"snap_game_true_pos_rt_avrg_change.0.2\", 30, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"education_level.0\", \"snap_game_true_pos_rt_avrg_change.0.2\", 1, \"nm_sg_pm_1_edu\", True)\n",
    "\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"age_visit.0\", \"pairs_matching_change_round_1.0.2\", 1, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"time_difference.0.2\", \"pairs_matching_change_round_1.0.2\", 30, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"education_level.0\", \"pairs_matching_change_round_1.0.2\", 1, \"nm_sg_pm_1_edu\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****')\n",
    "print(\" Speed all thre cognitive tests, pm round 1\")\n",
    "\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"age_visit.0\", \"numeric_memory_change_rate.0.2\", 1, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"time_difference.0.2\", \"numeric_memory_change_rate.0.2\", 30, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"education_level.0\", \"numeric_memory_change_rate.0.2\", 1, \"nm_sg_pm_1_edu\", True)\n",
    "\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"age_visit.0\", \"snap_game_true_pos_rt_avrg_change_rate.0.2\", 1, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"time_difference.0.2\", \"snap_game_true_pos_rt_avrg_change_rate.0.2\", 30, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"education_level.0\", \"snap_game_true_pos_rt_avrg_change_rate.0.2\", 1, \"nm_sg_pm_1_edu\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"age_visit.0\", \"pairs_matching_change_rate_round_1.0.2\", 1, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"time_difference.0.2\", \"pairs_matching_change_rate_round_1.0.2\", 30, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"education_level.0\", \"pairs_matching_change_rate_round_1.0.2\", 1, \"nm_sg_pm_1_edu\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all thre cognitive tests, pm 2 rounds\n",
    "\n",
    "print('****')\n",
    "print(\"Change all thre cognitive tests, pm 2 rounds\")\n",
    "\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"age_visit.0\", \"numeric_memory_change.0.2\", 1, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"time_difference.0.2\", \"numeric_memory_change.0.2\", 30, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"education_level.0\", \"numeric_memory_change.0.2\", 1, \"nm_sg_pm_edu\", True)\n",
    "\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"age_visit.0\", \"snap_game_true_pos_rt_avrg_change.0.2\", 1, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"time_difference.0.2\", \"snap_game_true_pos_rt_avrg_change.0.2\", 30, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"education_level.0\", \"snap_game_true_pos_rt_avrg_change.0.2\", 1, \"nm_sg_pm_edu\", True)\n",
    "\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"age_visit.0\", \"pairs_matching_sum_incorrect_change.0.2\", 1, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"time_difference.0.2\", \"pairs_matching_sum_incorrect_change.0.2\", 30, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"education_level.0\", \"pairs_matching_sum_incorrect_change.0.2\", 1, \"nm_sg_pm_edu\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all thre cognitive tests, pm 2 rounds\n",
    "\n",
    "print('****')\n",
    "print(\"Speed all thre cognitive tests, pm 2 rounds\")\n",
    "\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"age_visit.0\", \"numeric_memory_change_rate.0.2\", 1, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"time_difference.0.2\", \"numeric_memory_change_rate.0.2\", 30, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"education_level.0\", \"numeric_memory_change.0.2\", 1, \"nm_sg_pm_edu\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"age_visit.0\", \"snap_game_true_pos_rt_avrg_change_rate.0.2\", 1, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"time_difference.0.2\", \"snap_game_true_pos_rt_avrg_change_rate.0.2\", 30, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"education_level.0\", \"snap_game_true_pos_rt_avrg_change_rate.0.2\", 1, \"nm_sg_pm_edu\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"age_visit.0\", \"pairs_matching_sum_incorrect_change_speed\", 1, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"time_difference.0.2\", \"pairs_matching_sum_incorrect_change_speed\", 30, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"education_level.0\", \"pairs_matching_sum_incorrect_change_speed\", 1, \"nm_sg_pm_edu\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "show_trends(df_checkup_nm_sg_edu, \"age_visit.0\", \"numeric_memory_change.0.2\", 1, \"nm_sg_with_edu\")\n",
    "show_trends(df_checkup_nm_sg_edu, \"time_difference.0.2\", \"numeric_memory_change.0.2\", 30, \"nm_sg_with_edu\")\n",
    "show_trends(df_checkup_nm_sg_edu, \"education_level.0\", \"numeric_memory_change.0.2\", 1, \"nm_sg_with_edu\", True)\n",
    "\n",
    "show_trends(df_checkup_nm_sg_edu, \"age_visit.0\", \"numeric_memory_change_rate.0.2\", 1, \"nm_sg_with_edu\")\n",
    "show_trends(df_checkup_nm_sg_edu, \"time_difference.0.2\", \"numeric_memory_change_rate.0.2\", 30, \"nm_sg_with_edu\")\n",
    "show_trends(df_checkup_nm_sg_edu, \"education_level.0\", \"numeric_memory_change_rate.0.2\", 1, \"nm_sg_with_edu\", True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****')\n",
    "print(\"Change & Speed pm_1 sg edu\")\n",
    "\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"age_visit.0\", \"pairs_matching_change_round_1.0.2\", 1, \"pm_1_sg\")\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"time_difference.0.2\", \"pairs_matching_change_round_1.0.2\", 30, \"pm_1_sg\")\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"education_level.0\", \"pairs_matching_change_round_1.0.2\", 1, \"pm_1_sg\", True)\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"age_visit.0\",\"time_difference.0.2\", 1, \"pm_1_sg_edu\")\n",
    "\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"age_visit.0\", \"pairs_matching_change_rate_round_1.0.2\", 1, \"pm_1_sg\")\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"time_difference.0.2\", \"pairs_matching_change_rate_round_1.0.2\", 30, \"pm_1_sg\")\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"education_level.0\", \"pairs_matching_change_rate_round_1.0.2\", 1, \"pm_1_sg\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****')\n",
    "print(\"Change & Speed pm_1 sg edu\")\n",
    "\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"age_visit.0\", \"snap_game_true_pos_rt_avrg_change.0.2\", 1, \"pm_1_sg_edu\")\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"time_difference.0.2\", \"snap_game_true_pos_rt_avrg_change.0.2\", 30, \"pm_1_sg_edu\")\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"education_level.0\", \"snap_game_true_pos_rt_avrg_change.0.2\", 1, \"pm_1_sg_edu\", True)\n",
    "\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"age_visit.0\", \"snap_game_true_pos_rt_avrg_change_rate.0.2\", 1, \"pm_1_sg_edu\")\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"time_difference.0.2\", \"snap_game_true_pos_rt_avrg_change_rate.0.2\", 30, \"pm_1_sg_edu\")\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"education_level.0\", \"snap_game_true_pos_rt_avrg_change_rate.0.2\", 1, \"pm_1_sg_edu\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('****')\n",
    "print(\"Change & Speed pm sg\")\n",
    "show_trends(df_checkup_pm_sg,\"age_visit.0\", \"pairs_matching_sum_incorrect_change.0.2\", 1, \"pm_sg\")\n",
    "show_trends(df_checkup_pm_sg, \"time_difference.0.2\", \"pairs_matching_sum_incorrect_change.0.2\", 30, \"pm_sg\")\n",
    "show_trends(df_checkup_pm_sg, \"education_level.0\", \"pairs_matching_sum_incorrect_change.0.2\", 1, \"pm_sg\", True)\n",
    "\n",
    "show_trends(df_checkup_pm_sg,\"age_visit.0\", \"pairs_matching_sum_incorrect_change_rate.0.2\", 1, \"pm_sg\")\n",
    "show_trends(df_checkup_pm_sg, \"time_difference.0.2\", \"pairs_matching_sum_incorrect_change_rate.0.2\", 30, \"pm_sg\")\n",
    "show_trends(df_checkup_pm_sg, \"education_level.0\", \"pairs_matching_sum_incorrect_change_rate.0.2\", 1, \"pm_sg\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3650\n",
    "b = 3850\n",
    "df_checkup_nm_sg_a_b = df_checkup_nm_sg[df_checkup_nm_sg[\"time_difference.0.2\"].ge(3500) &\n",
    "                                                  df_checkup_nm_sg[\"time_difference.0.2\"].le(3750)]\n",
    "df_checkup_nm_sg_a_b[\"time_difference.0.2\"].plot(kind='hist', title='Density time_difference.0.2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"a={a}\")\n",
    "print(f\"b={b}\")\n",
    "show_trends(df_checkup_nm_sg_a_b, \"age_visit.0\",\"numeric_memory_change.0.2\", 1, \"nm_sg_a_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****')\n",
    "print(\"Change & Speed pm_1 sg visits 0 1\")\n",
    "show_trends(df_01_checkup_pm_1_sg,\"age_visit.0\", \"pairs_matching_change_round_1.0.1\", 1, \"pm_sg\")\n",
    "show_trends(df_01_checkup_pm_1_sg, \"time_difference.0.1\", \"pairs_matching_change_round_1.0.1\", 30, \"pm_sg\")\n",
    "show_trends(df_01_checkup_pm_1_sg, \"education_level.0\", \"pairs_matching_change_round_1.0.1\", 1, \"pm_sg\", True)\n",
    "\n",
    "show_trends(df_01_checkup_pm_1_sg,\"age_visit.0\", \"pairs_matching_change_rate_round_1.0.1\", 1, \"pm_sg\")\n",
    "show_trends(df_01_checkup_pm_1_sg, \"time_difference.0.1\", \"pairs_matching_change_rate_round_1.0.1\", 30, \"pm_sg\")\n",
    "show_trends(df_01_checkup_pm_1_sg, \"education_level.0\", \"pairs_matching_change_rate_round_1.0.1\", 1, \"pm_sg\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('****')\n",
    "print(\"Change & Speed pm sg visits 0 1\")\n",
    "show_trends(df_01_checkup_pm_sg,\"age_visit.0\", \"pairs_matching_sum_incorrect_change.0.1\", 1, \"pm_sg\")\n",
    "show_trends(df_01_checkup_pm_sg, \"time_difference.0.1\", \"pairs_matching_sum_incorrect_change.0.1\", 30, \"pm_sg\")\n",
    "show_trends(df_01_checkup_pm_sg, \"education_level.0\", \"pairs_matching_sum_incorrect_change.0.1\", 1, \"pm_sg\", True)\n",
    "\n",
    "show_trends(df_01_checkup_pm_sg,\"age_visit.0\", \"pairs_matching_sum_incorrect_change_rate.0.1\", 1, \"pm_sg\")\n",
    "show_trends(df_01_checkup_pm_sg, \"time_difference.0.1\", \"pairs_matching_sum_incorrect_change_rate.0.1\", 30, \"pm_sg\")\n",
    "show_trends(df_01_checkup_pm_sg, \"education_level.0\", \"pairs_matching_sum_incorrect_change_rate.0.1\", 1, \"pm_sg\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(df_source, predictors, outcome_var, run_lasso = True):\n",
    "    print(f\"outcome: {outcome_var}\")\n",
    "    print(df_source.columns)\n",
    "    X = df_source.loc[:,predictors]\n",
    "    scaler = StandardScaler()\n",
    "    y = df_source[outcome_var]\n",
    "    # Initialize LassoCV with 10-fold cross-validation\n",
    "    if (run_lasso) {\n",
    "      \n",
    "        lasso_cv = LassoCV(cv=100, random_state=42, max_iter=10000)\n",
    "        pipeline = make_pipeline(scaler, lasso_cv)\n",
    "        pipeline.fit(X, y)\n",
    "        print(\"Predictors:\")\n",
    "        print(predictors)\n",
    "    \n",
    "        # Optimal alpha value\n",
    "        print(f\"Optimal alpha: {lasso_cv.alpha_}\")\n",
    "\n",
    "        # Coefficients\n",
    "        print(f\"Coefficients: {lasso_cv.coef_}\")\n",
    "\n",
    "        # Intercept\n",
    "        print(f\"Intercept: {lasso_cv.intercept_}\")\n",
    "        print(\"Linear mode builder\")\n",
    "\n",
    "        corrected_predictors = []\n",
    "        for i in range(len(predictors)):\n",
    "            if lasso_cv.coef_[i] != 0:\n",
    "                corrected_predictors = corrected_predictors + [predictors[i]]\n",
    "   \n",
    "        if len(corrected_predictors)== 0:\n",
    "            print(\"All teh coefficients are zeros, I ignore lasso outcome\")\n",
    "            corrected_predictors = predictors\n",
    "           \n",
    "    } else {\n",
    "        corrected_predictors = predictors\n",
    "    }\n",
    "    \n",
    "    X_corr = df_source.loc[:,corrected_predictors]\n",
    "    for clmn in  X_corr.columns:   \n",
    "         X_corr[clmn] = (X_corr[clmn] - X_corr[clmn].mean())/X_corr[clmn].std()\n",
    "    \n",
    "    X_corr = sm.add_constant(X_corr)\n",
    "    model = sm.OLS(y, X_corr).fit()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_checkup_nm_sg_pm_1_edu[\"log_age.0\"] =  np.log(df_checkup_nm_sg_pm_1_edu[\"age_visit.0\"])\n",
    "df_checkup_nm_sg_pm_edu[\"log_age.0\"] =  np.log(df_checkup_nm_sg_pm_edu[\"age_visit.0\"])\n",
    "\n",
    "df_checkup_pm_1_sg_edu[\"log_age.0\"] =  np.log(df_checkup_pm_1_sg_edu[\"age_visit.0\"])\n",
    "df_checkup_pm_sg_edu[\"log_age.0\"] =  np.log(df_checkup_pm_sg_edu[\"age_visit.0\"])\n",
    "\n",
    "df_checkup_nm_sg_edu[\"log_age.0\"] =  np.log(df_checkup_nm_sg_edu[\"age_visit.0\"])\n",
    "\n",
    "predictors=[\"log_time_difference.0.2\",\"education_level.0\", \"age_visit.0\", \"log_age.0\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_builder(df_checkup_nm_sg_pm_1_edu, predictors, \"numeric_memory_change.0.2\")\n",
    "model_builder(df_checkup_nm_sg_pm_1_edu, predictors, \"pairs_matching_change_round_1.0.2\")\n",
    "model_builder(df_checkup_nm_sg_pm_1_edu, predictors, \"snap_game_true_pos_rt_avrg_change.0.2\")\n",
    "\n",
    "model_builder(df_checkup_nm_sg_pm_1_edu, predictors, \"numeric_memory_change_rate.0.2\")\n",
    "model_builder(df_checkup_nm_sg_pm_1_edu, predictors, \"pairs_matching_change_rate_round_1.0.2\")\n",
    "model_builder(df_checkup_nm_sg_pm_1_edu, predictors, \"snap_game_true_pos_rt_avrg_change_rate.0.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_builder(df_checkup_nm_sg_pm_edu, predictors, \"numeric_memory_change.0.2\")\n",
    "model_builder(df_checkup_nm_sg_pm_edu, predictors, \"pairs_matching_sum_incorrect_change.0.2\")\n",
    "model_builder(df_checkup_nm_sg_pm_edu, predictors, \"snap_game_true_pos_rt_avrg_change.0.2\")\n",
    "\n",
    "model_builder(df_checkup_nm_sg_pm_edu, predictors, \"numeric_memory_change_rate.0.2\")\n",
    "model_builder(df_checkup_nm_sg_pm_edu, predictors, \"pairs_matching_sum_incorrect_change_rate.0.2\")\n",
    "model_builder(df_checkup_nm_sg_pm_edu, predictors, \"snap_game_true_pos_rt_avrg_change_rate.0.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_builder(df_checkup_pm_1_sg_edu, predictors, \"pairs_matching_change_round_1.0.2\")\n",
    "model_builder(df_checkup_pm_1_sg_edu, predictors, \"snap_game_true_pos_rt_avrg_change.0.2\")\n",
    "\n",
    "\n",
    "model_builder(df_checkup_pm_1_sg_edu, predictors, \"pairs_matching_change_speed_round_1.0.2\")\n",
    "model_builder(df_checkup_pm_1_sg_edu, predictors, \"snap_game_true_pos_rt_avrg_change_rate.0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_builder(df_checkup_pm_sg_edu, predictors, \"pairs_matching_sum_incorrect_change.0.2\")\n",
    "model_builder(df_checkup_pm_sg_edu, predictors, \"snap_game_true_pos_rt_avrg_change.0.2\")\n",
    "\n",
    "model_builder(df_checkup_pm_sg_edu, predictors, \"pairs_matching_sum_incorrect_change_rate.0.2\")\n",
    "model_builder(df_checkup_pm_sg_edu, predictors, \"snap_game_true_pos_rt_avrg_change_rate.0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder(df_checkup_nm_sg_edu, predictors, \"numeric_memory_change.0.2\")\n",
    "model_builder(df_checkup_nm_sg_edu, predictors, \"snap_game_true_pos_rt_avrg_change.0.2\")\n",
    "\n",
    "model_builder(df_checkup_nm_sg_edu, predictors, \"numeric_memory_change_rate.0.2\")\n",
    "model_builder(df_checkup_nm_sg_edu, predictors, \"snap_game_true_pos_rt_avrg_change_rate.0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trends(df_checkup_nm_sg_pm_1_edu, \"age_visit.0\",\"time_difference.0.2\", 1, \"nm_sg_pm_1_edu\")\n",
    "show_trends(df_checkup_nm_sg_pm_edu, \"age_visit.0\",\"time_difference.0.2\", 1, \"nm_sg_pm_edu\")\n",
    "show_trends(df_checkup_pm_1_sg_edu, \"age_visit.0\",\"time_difference.0.2\", 1, \"pm_1_sg_edu\")\n",
    "show_trends(df_checkup_pm_sg_edu, \"age_visit.0\",\"time_difference.0.2\", 1, \"pm_sg_edu\")\n",
    "show_trends(df_checkup_nm_sg_edu, \"age_visit.0\",\"time_difference.0.2\", 1, \"nm_sg_edu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copula",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
