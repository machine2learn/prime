{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "    \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import copy\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = None # if none then all data points are taken, otherwise only the first n_samples, used for debugging\n",
    "\n",
    "\n",
    "lasso_epsilon = 0.01\n",
    "p_val = 0.05\n",
    "age_limit = 0\n",
    "gender = None\n",
    "gender_column = \"Sex\"\n",
    "iqr_coefficient = 1.5 # if None then no standrat removal of outliers\n",
    "\n",
    "simple_predictors =[\"Age\", \"BMI\"]\n",
    "predictors = [\"HighBP\", \"HighChol\", \"CholCheck\", \"BMI\",\"Smoker\", \"Stroke\", \n",
    "              \"HeartDiseaseorAttack\", \"MentHlth\", \"PhysActivity\", \"DiffWalk\", \"Fruits\", \"Veggies\", \"HvyAlcoholConsump\", \n",
    "             \"AnyHealthcare\", \"NoDocbcCost\", \"Sex\",  \"Age\", \"Education\", \"Income\"]\n",
    "\n",
    "binarys = [\"HighBP\", \"HighChol\"]\n",
    "\n",
    "# set your outcome variable here\n",
    "outcome =  \"Diabetes_012\"\n",
    "\n",
    "\n",
    "HSCD = 'HC1' # if None than the model builder will be heteroscedascisity unaware\n",
    "remove_na = True # must be set to true for input data set with the NA values present\n",
    "\n",
    "# set your wokring directory here, it containes input csv file and will contain output files (model)\n",
    "\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "working_dir = f\"{home_directory}/PRIME/example_data\"\n",
    "\n",
    "# source https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators\n",
    "# source https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset?resource=download\n",
    "# set locations of your input csv data set here\n",
    "input_file = f\"{working_dir}/diabetes_012_health_indicators_BRFSS2015.csv\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned check up db has 253680 rows\n",
      "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
      "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
      "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
      "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
      "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
      "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
      "\n",
      "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
      "0                   0.0           0.0     0.0  ...            1.0   \n",
      "1                   0.0           1.0     0.0  ...            0.0   \n",
      "2                   0.0           0.0     1.0  ...            1.0   \n",
      "3                   0.0           1.0     1.0  ...            1.0   \n",
      "4                   0.0           1.0     1.0  ...            1.0   \n",
      "\n",
      "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
      "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
      "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
      "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
      "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
      "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
      "\n",
      "   Income  \n",
      "0     3.0  \n",
      "1     1.0  \n",
      "2     8.0  \n",
      "3     6.0  \n",
      "4     4.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "/Users/olhashkaravska/PRIME/example_data/non_na_Diabetes_012_HSCD_HC1/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# read the input data set\n",
    "df = pd.read_table(input_file, nrows=n_samples, sep=',')\n",
    "\n",
    "# creating output directory within the working directory, the name of the output directory will tell how model is build\n",
    "# the creation of the output name follows straightforward from the code frgament below\n",
    "\n",
    "outcome_dir = outcome.replace(',', '_').replace('/', '_').replace(' ', '')\n",
    "if \"imputed\" in input_file:\n",
    "  output_dir = f\"{working_dir}/imputed_{outcome_dir}\"\n",
    "else:\n",
    "  df = df.dropna(axis=\"rows\")\n",
    "  print(f\"cleaned check up db has {len(df)} rows\")\n",
    "  output_dir = f\"{working_dir}/non_na_{outcome_dir}\"\n",
    "  \n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "if HSCD is not None:\n",
    "  output_dir = f\"{output_dir}_HSCD_{HSCD}\"\n",
    "\n",
    "if gender is None:\n",
    "  output_dir = f\"{output_dir}/\"\n",
    "else:\n",
    "  output_dir = f\"{output_dir}_gender_{gender}\"\n",
    "  df = df[df[gender_column].eq(gender)]\n",
    "  df = df.drop(columns=[gender_column])\n",
    "  predictors.remove(gender_column)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "  os.makedirs(output_dir)\n",
    "\n",
    "print(output_dir)\n",
    "\n",
    "# finished creating output directory\n",
    "  \n",
    "# we need to check for each predictor if  not all its values are zeros\n",
    "for predictor in binarys:\n",
    "    if df[predictor].eq(1).sum() == 0:\n",
    "      df = df.drop(columns=[predictor])\n",
    "      predictors.remove(predictor)\n",
    "      print(f\"dropped column because all zeroes: {predictor}\")\n",
    "    if df[predictor].eq(0).sum() == 0:\n",
    "      df = df.drop(columns=[predictor])\n",
    "      predictors.remove(predictor)\n",
    "      print(f\"dropped column because all ones: {predictor}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned check up db has 253680 rows\n"
     ]
    }
   ],
   "source": [
    "df = df[predictors+[outcome]]\n",
    "if remove_na:\n",
    "    df = df.dropna(axis=\"rows\")\n",
    "    print(f\"cleaned check up db has {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (gender is not None) and (gender_column in simple_predictors):\n",
    "    simple_predictors.remove(gender_column) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_predictors = predictors\n",
    "for predictor in global_predictors:\n",
    "    if predictor not in df.columns:\n",
    "        print(f\"predictor column  is missing {predictor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(df_source, predictors, outcome_var, result_dir, hcd):\n",
    "    \n",
    "    if not os.path.exists(result_dir):\n",
    "    # The directory does not exist, create it\n",
    "        os.makedirs(result_dir)\n",
    "        \n",
    "    y = df_source[outcome_var]\n",
    "    print(f\"outcome: {y}\")\n",
    "    \n",
    "    X = df_source[predictors]\n",
    "        \n",
    "  \n",
    "    # getting basic statistics for all predictors and standartising on the flow\n",
    "   \n",
    "    df_mean_std = pd.DataFrame(columns = [\"predictor\", \"mean\", \"standard_deviation\", \"min\", \"max\"] )\n",
    "    \n",
    "    predictors = X.columns \n",
    "    for i in  range(len(predictors)):  \n",
    "        clmn = predictors[i]\n",
    "        mean_ = X[clmn].mean()\n",
    "        std_ = X[clmn].std()\n",
    "        df_mean_std.loc[i] = [clmn, mean_, std_, X[clmn].min(), X[clmn].max()]\n",
    "        X[clmn] = (X[clmn] - mean_)/std_\n",
    "        \n",
    "   \n",
    "    X_with_intercept = sm.add_constant(X) \n",
    "    if hcd is not None:\n",
    "        model_1= sm.OLS(y, X_with_intercept).fit(cov_type=hcd) \n",
    "    else:\n",
    "        model_1= sm.OLS(y, X_with_intercept).fit() \n",
    "    \n",
    "    \n",
    "    with open(f\"{result_dir}/simle_ols_model_summary.txt\", 'w') as model_1_file:\n",
    "    # Convert the summary to a string and write it to the file\n",
    "        model_1_file.write(model_1.summary().as_text())\n",
    "    \n",
    "    coefficients = model_1.params\n",
    "    p_values = model_1.pvalues\n",
    "    df_results = pd.DataFrame({'Coefficient': coefficients, 'P_value': p_values})\n",
    "    \n",
    "    df_results = df_results.reset_index()\n",
    "    df_results = df_results.rename(columns={df_results.columns[0]: 'predictor'})\n",
    "    df_results = pd.merge(df_results, df_mean_std, on = \"predictor\", how = 'outer')\n",
    "    \n",
    "    df_results.to_csv(f\"{result_dir}/simple_ols_model_with_stats.csv\", sep=',')\n",
    "  \n",
    "    return df_results, model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_model_builder(df_source, predictors, outcome_var, result_dir, hcd):\n",
    "    \n",
    "    if not os.path.exists(result_dir):\n",
    "    # The directory does not exist, create it\n",
    "        os.makedirs(result_dir)\n",
    "        \n",
    "    y = df_source[outcome_var]\n",
    "    print(f\"outcome: {y}\")\n",
    "    \n",
    "    X = df_source[predictors]\n",
    "   \n",
    "    \n",
    "    ############ LASSO ###### \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    # Initialize LassoCV with 100-fold cross-validation\n",
    "    lasso_cv = LassoCV(cv=100, random_state=42, max_iter=10000)\n",
    "    pipeline = make_pipeline(scaler, lasso_cv)\n",
    "    pipeline.fit(X, y)\n",
    "        \n",
    "    lasso_cv_fitted = pipeline.named_steps['lassocv']\n",
    "    \n",
    "    summary_text = f\"Best alpha (regularization strength): {lasso_cv_fitted.alpha_}\\n\"\n",
    "    summary_text += f\"Intercept {lasso_cv_fitted.intercept_}\\nCoefficients:\\n\"\n",
    "    summary_text += f\"{lasso_cv_fitted.coef_}\\n\"\n",
    "    summary_text += f\"MSE path {lasso_cv_fitted.mse_path_}\\n\"\n",
    "        \n",
    "    r2_score = pipeline.score(X, y)\n",
    "    summary_text += f\"R^2 score: {r2_score}\"\n",
    "   \n",
    "    with open(f\"{result_dir}/intermediate_results_lasso_technical_summary.txt\", 'w') as lasso_file:\n",
    "        lasso_file.write(summary_text)\n",
    "    \n",
    "    # preparing the list of predictors with non zero coefficients (large enough)\n",
    "    if abs(lasso_cv_fitted.intercept_) >=  lasso_epsilon:\n",
    "        selected_features = [\"const\"]  \n",
    "    else:  \n",
    "        selected_features = []\n",
    "        \n",
    "    for i in range(len(predictors)):\n",
    "        if abs(lasso_cv_fitted.coef_[i])>= lasso_epsilon:\n",
    "            selected_features = selected_features + [predictors[i]]\n",
    "   \n",
    "    \n",
    "    # getting coefficients and basic statistics for all predictors, incl const\n",
    "   \n",
    "    df_mean_std = pd.DataFrame(columns = [\"predictor\", \"Coefficient\", \"mean\", \"standard_deviation\", \"min\", \"max\"] )\n",
    "    df_mean_std.loc[0] = [\"const\", lasso_cv_fitted.intercept_, lasso_cv_fitted.intercept_, 0, lasso_cv_fitted.intercept_, lasso_cv_fitted.intercept_]\n",
    "    X_scaled = df_source[predictors]\n",
    "    for i in  range(len(predictors)):  \n",
    "        clmn = predictors[i]\n",
    "        \n",
    "        mean_ = X_scaled[clmn].mean()\n",
    "        std_ = X_scaled[clmn].std()\n",
    "        df_mean_std.loc[i+1] = [clmn, lasso_cv_fitted.coef_[i], mean_, std_, X_scaled[clmn].min(), X_scaled[clmn].max()]\n",
    "        X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
    "        \n",
    "    ## getting p-values for all predictors via ols model\n",
    "   \n",
    "    X_scaled_with_intercept = sm.add_constant(X_scaled) \n",
    "    if hcd is not None:\n",
    "        model_1 = sm.OLS(y, X_scaled_with_intercept).fit(cov_type=hcd) \n",
    "    else:\n",
    "        model_1 = sm.OLS(y, X_scaled_with_intercept).fit() \n",
    "    \n",
    "    \n",
    "    # with open(f\"{result_dir}/ols_model_summary.txt\", 'w') as model_1_file:\n",
    "    # Convert the summary to a string and write it to the file\n",
    "        # model_1_file.write(model_1.summary().as_text())\n",
    "    \n",
    "    coefficients = model_1.params\n",
    "    p_values = model_1.pvalues\n",
    "    df_results = pd.DataFrame({'OLS_Coefficient': coefficients, 'P_value': p_values})\n",
    "    \n",
    "    df_results = df_results.reset_index()\n",
    "    df_results = df_results.rename(columns={df_results.columns[0]: 'predictor'})\n",
    "    df_results = pd.merge(df_results, df_mean_std, on = \"predictor\", how = 'outer')\n",
    "    \n",
    "    df_results.to_csv(f\"{result_dir}/intermediate_results_lasso_readable.csv\", sep=',')\n",
    "    \n",
    "    # creating OLS model based on selected predictors \n",
    "    if 'const' in selected_features:\n",
    "        selected_features.remove('const')\n",
    "        \n",
    "    X_selected = X_scaled[selected_features]\n",
    "    X_selected_with_intercept = sm.add_constant(X_selected) \n",
    "    if hcd is not None:\n",
    "        model_2= sm.OLS(y, X_selected_with_intercept).fit(cov_type=hcd) \n",
    "    else:\n",
    "        model_2= sm.OLS(y, X_selected_with_intercept).fit() \n",
    "        \n",
    "    with open(f\"{result_dir}/final_aftre_lasso_OSL_model_summary.txt\", 'w') as model_2_file:\n",
    "    # Convert the summary to a string and write it to the file\n",
    "        model_2_file.write(model_2.summary().as_text())\n",
    "        \n",
    "    \n",
    "    coefficients_2 = model_2.params\n",
    "    p_values_2 = model_2.pvalues\n",
    "    df_selected_results = pd.DataFrame({'OLS_Coefficient': coefficients_2, 'P_value': p_values_2})\n",
    "    \n",
    "    df_selected_results = df_selected_results.reset_index()\n",
    "    df_selected_results = df_selected_results.rename(columns={df_selected_results.columns[0]: 'predictor'})\n",
    "    df_selected_results = pd.merge(df_selected_results, df_mean_std, on = \"predictor\", how = 'outer')\n",
    "    \n",
    "    df_selected_results = df_selected_results[df_selected_results['predictor'].isin(selected_features + ['const'])]\n",
    "    df_selected_results.to_csv(f\"{result_dir}/final_after_lasso_OSL_model_with_stats.csv\", sep=',')\n",
    "    \n",
    "    return df_selected_results, model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dependencies(df_, model_df, predictors_to_show, dir):\n",
    "    \n",
    "    if model_df is None:\n",
    "        return\n",
    "    \n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "    \n",
    "    print(\"we are building graphs\")\n",
    "    \n",
    "    for predictor in predictors_to_show:\n",
    "        \n",
    "        \n",
    "        print(predictor)\n",
    "       \n",
    "        y = np.zeros(df_.shape[0])\n",
    "        # \n",
    "        # aggregate all the terms containing pedictor \n",
    "        for feat in model_df['predictor']:\n",
    "            if not predictor in feat:\n",
    "                continue\n",
    "            if not feat in df_.columns:\n",
    "                continue\n",
    "            print(feat)\n",
    "            \n",
    "            # prepare the feature\n",
    "            match feat:\n",
    "                case _ if feat == predictor:\n",
    "                    fun_pred = df_[predictor]\n",
    "                case _ if feat == f\"log_{predictor}\":\n",
    "                    fun_pred = np.log1p(df_[predictor])\n",
    "                case _ if feat == f\"quadr_{predictor}\":\n",
    "                    fun_pred = np.square(df_[predictor])\n",
    "                case _ if feat == f\"quadr_log_{predictor}\":\n",
    "                    fun_pred = np.square(np.log1p(df_[predictor]))\n",
    "                case _:\n",
    "                    fun_pred = None\n",
    "                    print(f\"error, non existing predictor {feat}\")\n",
    "            # standartise the feature\n",
    "            fun_pred = (fun_pred - fun_pred.mean())/fun_pred.std()\n",
    "            \n",
    "            \n",
    "            \n",
    "            # find the coefficient\n",
    "            row_feat = model_df[model_df['predictor'] == feat].iloc[0]\n",
    "            coeff =  row_feat[\"Coefficient\"]\n",
    "            \n",
    "            y = y + coeff *fun_pred\n",
    "        \n",
    "        # x_pred = (df_[predictor]    - df_[predictor].mean()) /  df_[predictor].std()\n",
    "        # x = np.linspace(min(x_pred), max(x_pred), 100)  \n",
    "          \n",
    "        are_all_zeros = np.all(y == 0)        \n",
    "        if not are_all_zeros:\n",
    "            x = df_[predictor]\n",
    "        \n",
    "            plt.scatter(x, y)\n",
    "            plt.xlabel(predictor)\n",
    "            plt.ylabel('outcome')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Save the plot as a PNG file\n",
    "            plt.savefig(f\"{dir}/{predictor}.png\", format='png', dpi=300)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome: 0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "253675    0.0\n",
      "253676    2.0\n",
      "253677    0.0\n",
      "253678    0.0\n",
      "253679    2.0\n",
      "Name: Diabetes_012, Length: 253680, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/2607438535.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_scaled[clmn] =  (X_scaled[clmn] - mean_)/std_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome: 0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "253675    0.0\n",
      "253676    2.0\n",
      "253677    0.0\n",
      "253678    0.0\n",
      "253679    2.0\n",
      "Name: Diabetes_012, Length: 253680, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/26120744.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[clmn] = (X[clmn] - mean_)/std_\n",
      "/var/folders/87/pb6c775x4ql_2tjlhmgjnh1w0000gn/T/ipykernel_32721/26120744.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[clmn] = (X[clmn] - mean_)/std_\n"
     ]
    }
   ],
   "source": [
    "if lasso_epsilon is not None :\n",
    "        \n",
    "    model_table, model = lasso_model_builder(df, global_predictors, outcome, f\"{output_dir}\",  HSCD)\n",
    "    model_table_simple, model_simple = model_builder(df, simple_predictors, outcome, f\"{output_dir}\",  HSCD)\n",
    "            \n",
    "else:\n",
    "\n",
    "    X = df[global_predictors]\n",
    "    y = df[outcome]\n",
    "    assert(len(X) == len(y))\n",
    "   \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "    \n",
    "    assert(len(X_train) == len(y_train))\n",
    "    assert(len(X_val) == len(y_val))\n",
    "    \n",
    "    '''\n",
    "    X_train, X_v0, y_train, y_v0 = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "    \n",
    "    assert(len(X_train) == len(y_train))\n",
    "    assert(len(X_v0) == len(y_v0))\n",
    "    \n",
    "    \n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_v0, y_v0, test_size=0.5, random_state=1)\n",
    "    assert(len(X_val) == len(y_val))\n",
    "    assert(len(X_test) == len(y_test))\n",
    "    '''\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # main model    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    # show_dependencies(df, model_table, predictors_to_plot, f\"{output_dir}/figures\")\n",
    "  \n",
    "    \n",
    "    y_pred_val = model.predict(X_val_scaled)\n",
    "   \n",
    "    mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    mse = mean_squared_error(y_val, y_pred_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred_val, squared=False)  # RMSE is the square root of MSE\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "    \n",
    "    validation_summary = f\"main model vaidation mean_absolute_error  { mae}\\n\"\n",
    "    validation_summary += f\"main model vaidation root mean_squared_error  {rmse}\\n\"\n",
    "    validation_summary += f\"main model vaidation R-squared (the coefficient of determination) {r2}\\n\"\n",
    "    \n",
    "    \n",
    "    # simple model      \n",
    "    X_train_simple = X_train[simple_predictors]\n",
    "    X_val_simple = X_val[simple_predictors]\n",
    "    scaler_simple = StandardScaler()\n",
    "    X_train_simple_scaled = scaler_simple.fit_transform(X_train_simple)\n",
    "    X_val_simple_scaled = scaler_simple.transform(X_val_simple)\n",
    "    \n",
    "    model_simple = LinearRegression()\n",
    "    model_simple.fit(X_train_simple_scaled, y_train)\n",
    "       \n",
    "    \n",
    "    y_simple_pred_val = model_simple.predict(X_val_simple_scaled)\n",
    "    mae_simple = mean_absolute_error(y_val, y_simple_pred_val)\n",
    "    mse_simple = mean_squared_error(y_val, y_simple_pred_val)\n",
    "    rmse_simple = mean_squared_error(y_val, y_simple_pred_val, squared=False)  # RMSE is the square root of MSE\n",
    "    r2_simple = r2_score(y_val, y_simple_pred_val)\n",
    "    \n",
    "    validation_summary += f\"simple model vaidation mean_absolute_error  { mae_simple}\\n\"\n",
    "    validation_summary += f\"simple model vaidation root mean_squared_error  {rmse_simple}\\n\"\n",
    "    validation_summary += f\"simple model vaidation model R-squared (the coefficient of determination) {r2_simple}\\n\"\n",
    "    \n",
    "    print(validation_summary)\n",
    "    with open(f\"{output_dir}/validation_summary_wo_lasso.txt\", 'w') as sum_file:\n",
    "        sum_file.write(validation_summary)\n",
    "    \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copula",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
