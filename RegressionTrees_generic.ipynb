{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import copy\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "\n",
    "n_samples = None # if none then all the datapoints will be loaded, otherwise (for debugging puproses) set the number of data points here\n",
    "remove_na = True # if True removes all the datapoints with at least one missed value; used for non-impuedt data set.\n",
    "\n",
    "gender_column = \"Sex\" # the name of the column where gender or sex is given\n",
    "gender = None # used for subsetting of the dataset by gender; if none, all the data points are considered\n",
    "iqr_coefficient = None# if None then no standrat removal of outliers is performed, othwerise used in Q1 - iqr_cf * (Q3-Q1)\n",
    "\n",
    "outcome = \"Diabetes_012\" \n",
    "\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "working_dir = f\"{home_directory}/PRIME/example_data\" # sets the working directory where the input output files are written in\n",
    "\n",
    "# https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators\n",
    "# https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset?resource=download\n",
    "input_file = f\"{working_dir}/diabetes_012_health_indicators_BRFSS2015.csv\"\n",
    "\n",
    "# creating output directory based on outcome name and gender if given\n",
    "outcome_dir = outcome.replace(',', '_').replace('/', '_').replace(' ', '')\n",
    "\n",
    "output_dir = f\"{working_dir}/tree_{outcome_dir}\"\n",
    "\n",
    "if gender is None:\n",
    "  output_dir = f\"{output_dir}/\"\n",
    "else:\n",
    "  output_dir = f\"{output_dir}_gender_{gender_column}/\"\n",
    "if not os.path.exists(output_dir):\n",
    "  os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "predictors = [ \"HighBP\", \"HighChol\", \"CholCheck\", \"BMI\",\"Smoker\", \"Stroke\", \n",
    "              \"HeartDiseaseorAttack\", \"MentHlth\", \"PhysActivity\", \"DiffWalk\", \"Fruits\", \"Veggies\", \"HvyAlcoholConsump\", \n",
    "             \"AnyHealthcare\", \"NoDocbcCost\", \"Sex\",  \"Age\", \"Education\", \"Income\"]\n",
    "\n",
    "# tree building algorithm specific parameters\n",
    "m_samples_split = 500\n",
    "m_samples_leaf = 250\n",
    "m_depth = 6\n",
    "\n",
    "# used in train and test split and in tree building\n",
    "RANDOM_STATE = 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for removing outliers via iqr approach\n",
    "def remove_outliers_iqr(df_, iqr_cf,  outliers):\n",
    "    print(f\"# data points before removing outliers: {len(df_)}\")\n",
    "    if iqr_cf is not None:\n",
    "        \n",
    "        lower_bound = {}\n",
    "        upper_bound = {}\n",
    "        \n",
    "        for feat  in outliers:\n",
    "            print(f\"{feat}\")\n",
    "            \n",
    "            Q1 = df_[feat].quantile(0.25)\n",
    "            Q3 = df_[feat].quantile(0.75)\n",
    "            \n",
    "            IQR = Q3-Q1\n",
    "            lower_bound[feat] = Q1 - iqr_cf * IQR\n",
    "            upper_bound[feat] = Q3 + iqr_cf * IQR\n",
    "            \n",
    "            \n",
    "            \n",
    "        for feat in lower_bound:\n",
    "            df_= df_[(df_[feat] >= lower_bound[feat]) & (df_[feat] <= upper_bound[feat])]\n",
    "            \n",
    "        print(f\"# data points after removing outliers: {len(df_)}\")\n",
    "    return(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV data import and subsetting\n",
    "df = pd.read_table(input_file, nrows=n_samples,sep =\",\")\n",
    "df = df[predictors+[outcome]]\n",
    "print(f\"data set {len(df)} rows\")\n",
    "if remove_na:\n",
    "    df = df.dropna(axis=\"rows\")\n",
    "    print(f\"cleaned check up db has {len(df)} rows\")\n",
    " \n",
    "if gender is not None:\n",
    "   df = df[df[gender_column].eq(gender) ]\n",
    "   predictors.remove(gender_column)\n",
    "   df = df.drop(columns=[gender_column], axis=1)\n",
    "       \n",
    "df = remove_outliers_iqr(df, iqr_coefficient, df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in df.columns if x not in [outcome, outcome]]\n",
    "# features = [x for x in df.columns if x not in outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test split \n",
    "X_train, X_val, y_train, y_val = train_test_split(df[features], df[outcome], train_size = 0.75, random_state = RANDOM_STATE)\n",
    "print(f'train samples: {len(X_train)}')\n",
    "print(f'validation samples: {len(X_val)}')\n",
    "min_ = df[outcome].min()\n",
    "max_ = df[outcome].max()\n",
    "median_ = df[outcome].median()\n",
    "mean_ = df[outcome].mean()\n",
    "print(f\"tr min {outcome}: {min_}\")\n",
    "print(f\"tr max {outcome}: {max_}\")\n",
    "print(f\"tr median {outcome}: {median_}\")\n",
    "print(f\"tr mean {outcome}: {mean_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute R1\n",
    "def r1(y_pred, y_true, median_):\n",
    "    abs_error_pred = (np.abs(y_true - y_pred)).sum()\n",
    "    abs_error = (np.abs(y_true - median_)).sum()\n",
    "    r1 = 1 -abs_error_pred/abs_error\n",
    "    return r1\n",
    "\n",
    "y_tr = pd.Series([1,2,3])\n",
    "m_ = y_tr.median()\n",
    "print(f\"test median {m_}\")\n",
    "y_pr = pd.Series([m_, m_, m_]) # \n",
    "test = r1(y_pr, y_tr, m_)\n",
    "print(f\"test r1 function: {test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree building and evaluation\n",
    "\n",
    "specific_name = f\"{m_samples_split}_{m_samples_leaf}_{m_depth}_{RANDOM_STATE}\"\n",
    "\n",
    "regressor = DecisionTreeRegressor(min_samples_leaf = m_samples_leaf,\n",
    "                                  min_samples_split =  m_samples_split,\n",
    "                                  max_depth = m_depth, \n",
    "                                  criterion = \"friedman_mse\",\n",
    "                                  random_state = RANDOM_STATE)\n",
    "\n",
    "regression_tree_model = regressor.fit(X_train,y_train)\n",
    "\n",
    "print(f\"MAE train:\\n\\t: {mean_absolute_error(regression_tree_model.predict(X_train),y_train):.4f}\")\n",
    "print(f\"MAE validation:\\n\\t: {mean_absolute_error(regression_tree_model.predict(X_val),y_val):.4f}\")\n",
    "print(f\"RMSE train:\\n\\t: {np.sqrt(mean_squared_error(regression_tree_model.predict(X_train),y_train)):.4f}\")\n",
    "print(f\"RMSE validation:\\n\\t: {np.sqrt(mean_squared_error(regression_tree_model.predict(X_val),y_val)):.4f}\")\n",
    "print(f\"R1 train:\\n\\t: {r1(regression_tree_model.predict(X_train),y_train,median_):.4f}\")\n",
    "print(f\"R1 validation:\\n\\t: {r1(regression_tree_model.predict(X_val),y_val, median_):.4f}\")\n",
    "print(f\"R2 train:\\n\\t: {r2_score(regression_tree_model.predict(X_train),y_train):.4f}\")\n",
    "print(f\"R2 validation:\\n\\t: {r2_score(regression_tree_model.predict(X_val),y_val):.4f}\")\n",
    "\n",
    "\n",
    "# Retrieve the feature importances\n",
    "importances = regression_tree_model.feature_importances_\n",
    "\n",
    "# Print the feature importances\n",
    "important_features = []\n",
    "important_importances = []\n",
    "df_importances = pd.DataFrame()\n",
    "\n",
    "for feature_name, importance in zip(features, importances):\n",
    "    if importance > 0:\n",
    "        important_features.append(feature_name)\n",
    "        important_importances.append(importance)\n",
    "        new_row = {'feature': feature_name, 'importance': importance}\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        df_importances = pd.concat([df_importances, new_row_df], ignore_index=True)\n",
    "        \n",
    "print(df_importances)       \n",
    "df_importances.to_csv(f\"{output_dir}/feature_importance_{m_samples_split}_{m_samples_leaf}_{specific_name}.csv\", sep =\",\")\n",
    "# Visualize the feature importances\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.barh(important_features, important_importances, align='center')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(f\"Feature Importances in DecisionTreeRegressor {specific_name}\")\n",
    "file_path = os.path.join(output_dir, f'feature_importances_{specific_name}.png')\n",
    "plt.savefig(file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree visualisation\n",
    "\n",
    "\n",
    "# adjusting colors\n",
    "values = regressor.tree_.value.flatten()\n",
    "# Normalize the values for coloring\n",
    "norm = plt.Normalize(values.min(), values.max())\n",
    "# Create a custom color map (green to red)\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\"GreenYellowRed\", [\"green\", \"yellow\", \"red\"])\n",
    "# cmap = mcolors.LinearSegmentedColormap.from_list(\"RedYellowGreen\", [\"red\", \"yellow\", \"green\"])\n",
    "\n",
    "# Generate colors for each node based on the normalized values and the custom color map\n",
    "colors = cmap(norm(values))\n",
    "\n",
    "dot_data_1 = export_graphviz(regressor,  out_file=None, filled=True, rounded=True, special_characters=True,\n",
    "                           feature_names=features,\n",
    "                           proportion=True)\n",
    "\n",
    "\n",
    "# Split the DOT data into lines\n",
    "dot_lines = dot_data_1.splitlines()\n",
    "hex_color_pattern = r'fillcolor=\"#[0-9a-fA-F]{6}\"'\n",
    "\n",
    "# Modify the DOT file lines to include custom colors\n",
    "new_dot_lines = []\n",
    "for line in dot_lines:\n",
    "    if 'fillcolor' in line:\n",
    "        parts = line.split()\n",
    "        if parts[0].isdigit():\n",
    "            node_id = int(parts[0])\n",
    "            # Get corresponding color\n",
    "            color = mcolors.to_hex(colors[node_id])\n",
    "            # Modify the line to include the color\n",
    "            line = re.sub(hex_color_pattern, f'fillcolor=\"{color}\"', line)\n",
    "    new_dot_lines.append(line)\n",
    "\n",
    "# Combine the modified lines back into a single string\n",
    "new_dot_data = \"\\n\".join(new_dot_lines)\n",
    "\n",
    "# Render the DOT file with Graphviz\n",
    "graph = graphviz.Source(new_dot_data)\n",
    "graph.render(f\"{outcome}_regression_tree_{specific_name}\", format='png')\n",
    "graph.render(f\"{output_dir}/{outcome}_regression_tree_{specific_name}\", format='png')\n",
    "graph.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for evaluating statistics for the node in a tree, given node's path\n",
    "\n",
    "def eval_node(X, y, logical_path, out_, interval_left, interval_right):\n",
    "    df_left = pd.concat([X, y], axis=1)\n",
    "    df_right = pd.concat([X, y], axis=1)\n",
    "    print(len(logical_path))\n",
    "    for i in range(len(logical_path)-1):\n",
    "        predicate = logical_path[i]\n",
    "        print(predicate)\n",
    "        if predicate[1] == \"le\":\n",
    "            df_left= df_left[df_left[predicate[0]].le(predicate[2])]\n",
    "            df_right= df_right[df_right[predicate[0]].le(predicate[2])]\n",
    "        else:\n",
    "            df_left = df_left[df_left[predicate[0]].gt(predicate[2])]\n",
    "            df_right = df_right[df_right[predicate[0]].gt(predicate[2])]\n",
    "        \n",
    "    predicate=logical_path[-1]\n",
    "    print(predicate)\n",
    "    df_left= df_left[df_left[predicate[0]].le(predicate[2])]\n",
    "    df_right = df_right[df_right[predicate[0]].gt(predicate[2])]\n",
    "            \n",
    "    median_left = df_left[out_].median()\n",
    "    q1_left = df_left[out_].quantile(0.25)\n",
    "    q3_left = df_left[out_].quantile(0.75)\n",
    "    mean_left = df_left[out_].mean()\n",
    "    std_left = df_left[out_].std()\n",
    "        \n",
    "    median_right = df_right[out_].median()\n",
    "    q1_right = df_right[out_].quantile(0.25)\n",
    "    q3_right = df_right[out_].quantile(0.75)\n",
    "    mean_right= df_right[out_].mean()\n",
    "    std_right = df_right[out_].std()\n",
    "        \n",
    "    if interval_left is not None:\n",
    "        n_within_interval_left = (df_left[out_].ge(interval_left[0]) & df_left[out_].le(interval_left[1])).sum()\n",
    "        percentage_within_interval_left = (n_within_interval_left * 100)/len(df_left)\n",
    "    else:\n",
    "        percentage_within_interval_left = None\n",
    "        \n",
    "    if interval_right is not None:\n",
    "        n_within_interval_right = (df_right[out_].ge(interval_left[0]) & df_right[out_].le(interval_left[1])).sum()\n",
    "        percentage_within_interval_right = (n_within_interval_right * 100)/len(df_right)\n",
    "    else:\n",
    "        percentage_within_interval_right = None\n",
    "        \n",
    "    ret_val = {\n",
    "            \"median\": [median_left,median_right],\n",
    "            \"q1\": [q1_left, q1_right],\n",
    "            \"q3\": [q3_left, q3_right],\n",
    "            \"mean\": [mean_left, mean_right],\n",
    "            \"std\": [std_left, std_right],\n",
    "            \"percentage_within_interval\": [percentage_within_interval_left, percentage_within_interval_right]\n",
    "        }\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of usage of eval_node function\n",
    "Walk_path = [['HighBP', \"gt\", 0.5],  [\"BMI\", \"gt\", 31.5], [\"HighChol\", \"gt\", 0.5], ['DiffWalk', \"gt\", 0.5]]\n",
    "tr_node_stat = eval_node(X_train, y_train, Walk_path, outcome, None, None)\n",
    "print(tr_node_stat)\n",
    "interval_left_waist = [tr_node_stat[\"mean\"][0] - tr_node_stat[\"std\"][0], tr_node_stat[\"mean\"][0] + tr_node_stat[\"std\"][0]]\n",
    "interval_right_waist = [tr_node_stat[\"mean\"][1] - tr_node_stat[\"std\"][1], tr_node_stat[\"mean\"][1] + tr_node_stat[\"std\"][1]]\n",
    "val_node_stat  = eval_node(X_val, y_val, Walk_path, outcome, interval_left_waist, interval_right_waist)\n",
    "print(val_node_stat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copula",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
